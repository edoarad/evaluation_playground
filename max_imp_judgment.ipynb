{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking for Maximum Impact\n",
    "\n",
    "We have a list of charities, $x_1,\\ldots,x_n$, and a list of expert judges $e_1,\\ldots,e_k$. Each expert judges some charities and gives them a numerical score $e_j(x_i)$. The scores are based on that expert's subjective judgement across a dozen or so criteria, each are scored with a number 1-5 and then are weightedly summed. \n",
    "\n",
    "Our question is: how do we rank the charities? \n",
    "\n",
    "## model\n",
    "\n",
    "Let's assume that each charity $x_i$ has a \"true\" value of $y_i$, which the experts are trying to estimate. \n",
    "\n",
    "The experts are additively and multiplicatively biased, and their scores are noisy. We model this as follows:\n",
    "\n",
    "$$ e_j(x_i) = m_j y_i + b_j + \\varepsilon_{j,i}$$\n",
    "\n",
    "where $m_j$ is the constant multiplicative bias for each expert $e_j$, $b_j$ is the constant additive bias, and $\\varepsilon_{j,i} \\sim \\text{N}(0,\\sigma_j)$ is the noise. All variables are assumed to be independent.\n",
    "\n",
    "## optimization\n",
    "\n",
    "We are looking for a solution that'd be the \"best\" fit. A solution would include all of the $y_i$'s, $m_j$'s, $b_j$'s, and $\\sigma_j$'s. Note that we have a couple of degrees of freedom here, which amount to changing all $y_i$ by a single linear transformation. We could solve that by normalizing the $y_i$ to have mean 0 and variance 1, for example.\n",
    "\n",
    "One option would be to define the best fit as the solution that maximizes the likelihood of the available estimates $e_j(x_i)$. After taking logarithm and dropping the constant terms, we get the following expression we want to maximize:\n",
    "\n",
    "$$ \\sum_{i,j} \\left( -\\frac{1}{2} \\log(2\\pi\\sigma_j^2) - \\frac{1}{2\\sigma_j^2} (e_j(x_i) - m_j y_i - b_j)^2 \\right) $$\n",
    "\n",
    "where the sum is over all charity/expert pair that's available. Equivalently, we can minimize\n",
    "\n",
    "$$ 2\\sum_j \\log(\\sigma_j) + \\sum_{i,j} \\frac{1}{2\\sigma_j^2} (e_j(x_i) - m_j y_i - b_j)^2 $$\n",
    "\n",
    "where the multiplier 2 is the number of charities each expert has (in our case).\n",
    "\n",
    "This is nearly a convex optimization problem, so we can use a standard solver to find the solution.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[$m_jy_i$ isn't convex. Also $1/\\sigma_j^2$ isn't convex]\n",
    "\n",
    "For simplicity, let's assume that all experts have the same error distribution, i.e. $\\sigma_j = \\sigma$ for all $j$. Thus, we get a least squares problem:\n",
    "\n",
    "$$ \\min_{y,m,b} \\sum_{i,j} (e_j(x_i) - m_j y_i - b_j)^2 $$\n",
    "\n",
    "In experiments below, this has problems converging. To solve this, we will estimate $m_j$ in two ways. First we will take it to be 1, and second we will estimate it from the data directly for each expert to normalize their own grades. We expect the truth to be somewhere in between, so we'll see how that affects the results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add a regularization term to make sure $b_j$ is small and we normalize the $e_j(x_i)$'s to have mean 0 and variance 1.\n",
    "\n",
    "Now, we can represent the problem as a matrix equation:\n",
    "\n",
    "$$ \\min_{y,b} \\| E - A(y,b) \\|_F^2 + \\lambda \\| b \\|_2^2 $$\n",
    "\n",
    "where $E$ is the matrix of expert scores, $A$ is a $nk,n+k$ matrix taking the concatenation of the vectors $y$ and $b$ to the estimate at each index, and $\\lambda$ is the regularization parameter. The matrix $A$ is defined as follows:\n",
    "\n",
    "$$ A_{(i,j),l} = \\begin{cases} \\delta_{i,l}m_j & \\text{if } l \\leq n \\\\ \\delta_{j,l} & \\text{otherwise} \\end{cases} $$\n",
    "\n",
    "where $\\delta$ is the Kronecker delta (1 if the indices are equal, 0 otherwise). We can then add extra rows to represent the regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./df_grades - Sheet1.csv')\n",
    "df['norm_grade'] = (df.grade - df.grade.mean()) / df.grade.std()\n",
    "df['m'] = 1\n",
    "charities = sorted(df['org'].unique())\n",
    "experts = sorted(df['judge'].unique())\n",
    "n = len(charities)\n",
    "k = len(experts)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix():\n",
    "    a = np.zeros([n*k + k, n+k])\n",
    "    for row in df.iterrows():\n",
    "        i = charities.index(row[1]['org'])\n",
    "        j = experts.index(row[1]['judge'])\n",
    "        m = row[1]['m']\n",
    "        a[i*k + j, i] = m\n",
    "        a[i*k + j, n + j] = 1\n",
    "    for j in range(k):\n",
    "        a[n*k + j, n + j] = 1\n",
    "    return a       \n",
    "\n",
    "def create_target_vector():\n",
    "    e = np.zeros(n*k + k)\n",
    "    \n",
    "    for row in df.iterrows():\n",
    "        i = charities.index(row[1]['org'])\n",
    "        j = experts.index(row[1]['judge'])\n",
    "        e[i*k + j] = row[1]['norm_grade']\n",
    "\n",
    "    # the last k values are 0\n",
    "\n",
    "    return e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = create_matrix()\n",
    "e = create_target_vector()\n",
    "sol = np.linalg.lstsq(a, e, rcond=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, b = sol[0][:n], sol[0][n:]\n",
    "sorted(list(zip(charities, y)), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(zip(experts, b)), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(np.dot(a, sol[0]) - e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets test this with $m_j$ calculated to normalize each judge's scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change df[m] to be the multiplicative normalization factor for each judge's grades\n",
    "\n",
    "df['m'] = 1\n",
    "for judge in experts:\n",
    "    df.loc[df['judge'] == judge, 'm'] = df.loc[df['judge'] == judge, 'norm_grade'].std()\n",
    "\n",
    "df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = create_matrix()\n",
    "e = create_target_vector()\n",
    "sol = np.linalg.lstsq(a, e, rcond=None)\n",
    "print(np.linalg.norm(np.dot(a, sol[0]) - e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(zip(charities, sol[0][:n])), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(zip(experts, sol[0][n:])), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a graph, where each node is a charity, and edges are differences in normalized grades per judge\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(charities)\n",
    "\n",
    "for judge in experts:\n",
    "    for c1, c2 in itertools.combinations(df.loc[df['judge'] == judge, 'org'], 2):\n",
    "        grade2 = df.loc[(df['judge'] == judge) & (df['org'] == c2), 'norm_grade'].values[0]\n",
    "        grade1 = df.loc[(df['judge'] == judge) & (df['org'] == c1), 'norm_grade'].values[0]\n",
    "        if grade1 > grade2:\n",
    "            G.add_edge(c2, c1, weight=grade1 - grade2)\n",
    "        else:\n",
    "            G.add_edge(c1, c2, weight=grade2 - grade1)\n",
    "\n",
    "def location(node, G=G):\n",
    "    index = list(nx.topological_sort(G)).index(node)\n",
    "    # return the location for that index on a circle\n",
    "    return (np.round(100 * np.cos(2*np.pi*index/n)), np.round(100 * np.sin(2*np.pi*index/n)))\n",
    "\n",
    "# nx.draw(G, with_labels=True, pos={node: location(node) for node in G.nodes()}, font_size=8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all cycles, with their weights\n",
    "cycles = sorted(nx.simple_cycles(G), key=lambda cycle: sum([G[cycle[i % len(cycle)]][cycle[(i+1) % len(cycle)]]['weight'] for i in range(len(cycle))]), reverse=True)\n",
    "for cycle in cycles:\n",
    "    print(cycle, sum([G[cycle[i % len(cycle)]][cycle[(i+1) % len(cycle)]]['weight'] for i in range(len(cycle))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(nx.recursive_simple_cycles(G)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['judge'] == judge, 'org']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['judge'] == judge) & (df['org'] == c1), 'norm_grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# position the charities according to their normalized grades\n",
    "\n",
    "pos = {node: (200 * df.loc[df['org'] == node, 'norm_grade'].mean() + 500, ((np.pi * sum(ord(c) for c in node)) % 1)*500 ) for node in G.nodes()}\n",
    "\n",
    "sorted_charities = sorted(charities, key=lambda charity: df.loc[df['org'] == charity, 'norm_grade'].mean(), reverse=True)\n",
    "\n",
    "nx.draw(G.subgraph(nodes=sorted_charities), pos=pos, font_size=5)\n",
    "nx.draw_networkx_labels(G.subgraph(nodes=sorted_charities), pos=pos, font_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol[0][:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# position the charities according to their normalized grades\n",
    "sorted(list(zip(charities, sol[0][:n])), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "pos = {node: (500 * sol[0][charities.index(node)] + 500, ((1000000* np.pi * sum(ord(c) for c in node)) % 1)*500 ) for node in G.nodes()}\n",
    "\n",
    "sorted_charities = sorted(charities, key=lambda charity: sol[0][charities.index(charity)], reverse=True)[:10]\n",
    "\n",
    "nx.draw(G.subgraph(nodes=sorted_charities), pos=pos, font_size=5)\n",
    "# draw the following nodes in red\n",
    "selected_nodes = ['Kav LaOved', 'MAF', 'NALA', 'Smoke free Israel', 'Isreali energy forum']\n",
    "nx.draw_networkx_nodes(G.subgraph(nodes=selected_nodes), pos=pos, node_color='r', node_size=100)\n",
    "nx.draw_networkx_labels(G.subgraph(nodes=sorted_charities), pos=pos, font_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the full graph, sorted by sorted_charities, removing all edges in the direction that agrees with the sorting\n",
    "sorted_charities = sorted(charities, key=lambda charity: sol[0][charities.index(charity)], reverse=True)\n",
    "G2 = nx.DiGraph()\n",
    "G2.add_nodes_from(sorted_charities)\n",
    "for c1, c2 in itertools.combinations(sorted_charities, 2):\n",
    "    if (c1, c2) in G.edges():\n",
    "        G2.add_edge(c1, c2, weight=G[c1][c2]['weight'])\n",
    "\n",
    "\n",
    "nx.draw(G2, with_labels=True, pos={node: location(node, G2) for node in G2.nodes()}, font_size=8)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "('20-80', 'NALA') in G.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c1 in sorted_charities:\n",
    "    if (c1, 'Tevel bzedek') in G.edges():\n",
    "        print(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c1 in sorted_charities:\n",
    "    if ('Tevel bzedek', c1) in G.edges():\n",
    "        print(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c1 in sorted_charities:\n",
    "    if (c1, 'Robin Food') in G.edges():\n",
    "        print(c1)\n",
    "\n",
    "print('------------')\n",
    "\n",
    "for c1 in sorted_charities:\n",
    "    if ('Robin Food', c1) in G.edges():\n",
    "        print(c1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
