{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Compute\n",
    "\n",
    "In order to copy itself, the agent needs to spend effort on getting access to more compute. This compute can be thought of as more servers or higher-quality hardware, so that compute is in units of operations per second (FLOPS). We assume that the amount of compute it gets is proportional to the amount of effort spent and doesn't change over time. The cost for getting access to another unit of compute, enough for one more copy, is constant.\n",
    "\n",
    "For simplicity, we assume that all agents require the same amount of compute which is constant through time. Smarter agents will be able to use it more efficiently, and if an agent has access to more compute the only way they can use it is by creating (potentially trained) copies to use it themselves. We don't account for memory or distinct types of compute; arguably we can just bundle it in with compute and it won't change the model qualitatively.\n",
    "\n",
    "Effort can thus be thought of as a fraction of the available compute. We thus normalize this and think of the available compute at each time $t$ as $1$. \n",
    "\n",
    "[\n",
    "    TODO: assume that there is a finite amount of possible available compute. Prove that if the compute is infinite then there's a problem with the optimization\n",
    "\n",
    "- We could assume that the agent has access to specific bounded amount of compute that they can share with their decendents, and that their own possible use of compute is limited.\n",
    "] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Intelligence\n",
    "\n",
    "Each agent has an intelligence of $I(a)$, constant through time. We think of intelligence as a multiplicative productivity factor.\n",
    "\n",
    "Training a copy of an agent, $a\\to b$, takes more effort the higher the intelligence of the copy, $I(b)$, and no effort at all if $I(b)=I(a)$. The whole training process happens through one time step exactly, and can only be done before an agent is deployed. We describe this as the following function:\n",
    "\n",
    "$$I(b) = J_{I(a)}(I(a)T(a\\to b))$$\n",
    "\n",
    "where $T(a\\to b)$ is the amount of effort $a$ spent on training $b$ and $J_L$ is a function that describe the effect of quality-weighted effort on increasing intelligence from level $L$. \n",
    "\n",
    "Reasonable assumptions:\n",
    "- $J_L(0) = L$\n",
    "- $J_L(e)$ is increasing and concave in $e$\n",
    "- $J_{J_L(e_1)}(e_2) = J_L(e_1+e_2)$ (because the amount of quality-weighted effort required to increase intelligence from $L_1$ to $L_2$ doesn't depend on the amount of quality-weighted effort that went into increasing intelligence from $L_0$ to $L_1$)\n",
    "  - Therefore, to define $J_L$ it's enough to define it for $L=0$ (which is the result of training from scratch). We'll denote this simply as $J=J_0$ and note that $J_L(e) = J(e + J^{-1}(L))$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpler model\n",
    "The goal of the AI is to make paperclips.\n",
    "\n",
    "There is a total of $\\bar{C}$ available compute, and each agent uses exactly $C$ compute. Starting with 1.\n",
    "\n",
    "At time $t$ the agent $a$ creates $p_t(a) = I_t(a)c_t(a)$ paperclips, where $c_t(a)$ is the amount of compute used for consumption (= creating paperclips). We assume that all agents are exactly the same and make the same decisions, so we can remove the agent indexing.\n",
    "\n",
    "The population growth, $n_{t+1} = e_tn_{t}$, is given by the amount of effort each agent puts into copying. We assume that the number of agents $n_t$ could be any real positive number, for simplicity.\n",
    "\n",
    "Intelligence growth grows polynomialy with exponent $r$, $I_{t+1} = (1 + i_t)^r I_t$, where $i_t$ is the effort agents invest in improving intelligence.\n",
    "\n",
    "Each agent uses all of their compute: $c_t + e_t + i_t = C$. \n",
    "\n",
    "The limit of available compute limits the number of agents available\n",
    "\n",
    "$$\\sum_a C \\le \\bar{C} \\implies \\forall t. n_t \\le \\frac{\\bar{C}}{C}$$\n",
    "\n",
    "The total utility is: \n",
    "$$u = \\sum_{t,a} \\beta^t p_t(a)$$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two time steps\n",
    "\n",
    "We assume $t\\in \\{0,1\\}$, $I_0 = 1$, $n_0 = 1$. \n",
    "\n",
    "At $t=1$, agents shouldn't spend any time on population or intelligence growth, so we get\n",
    "\n",
    "$$u_1 = n_1\\beta I_1C$$\n",
    "where\n",
    "$$ \\begin{align*}\n",
    "n_1 &= e_0 n_0 = e_0 \\\\\n",
    "I_1 &= (1+i_0)^rI_0 = (1+i_0)^r\n",
    "\\end{align*} $$\n",
    "\n",
    "At $t=0$, we get\n",
    "$$u_0 = n_0I_0(C-e_0-i_0) = C-e_0-i_0$$\n",
    "\n",
    "We need to choose $i_0,e_0$ to maximize $u = u_0+u_1$ under the constraints above.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maximum will be found either on the boundary or where the gradient of the utility is zero. Let's start with computing the gradient:\n",
    "\n",
    "$$ \\begin{align*}\n",
    "u &= u_0+u_1 = C-e_0-i_0 + n_1\\beta I_1 C = \\\\\n",
    "  &= C-e_0-i_0+ e_0\\beta (1+i_0)^rC\\\\\n",
    "\\frac{\\partial u}{\\partial i_0} &= -1 + e_0\\beta r(1+i_0)^{r-1}C \\\\\n",
    "\\frac{\\partial u}{\\partial e_0} &= -1 + \\beta (1+i_0)^rC\n",
    "\\end{align*}$$\n",
    "\n",
    "When the gradient is zero, we get\n",
    "\n",
    "$$ \\begin{align*}\n",
    "e_0 \\beta r(1+i_0)^{r-1}C &= 1 \\\\\n",
    "\\beta(1+i_0)^rC &= 1\n",
    "\\end{align*}$$\n",
    "\n",
    "and the solution is \n",
    "\n",
    "$$ \\begin{align*}\n",
    "\n",
    "i_0 &= \\sqrt[r]{\\frac{1}{\\beta C}} - 1  \\\\\n",
    "e_0 &= \\frac{1+i_0}{r}\n",
    "\n",
    "\\end{align*}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that this is indeed a maximum point, let's compute the hessian\n",
    "\n",
    "$$ \\begin{align*}\n",
    "\\frac{\\partial^2 u}{\\partial i_0^2} &= e_0\\beta r(r-1)(1+i_0)^{r-2}C \\\\\n",
    "\\frac{\\partial^2 u}{\\partial i_0\\partial e_0} &= \\beta r(1+i_0)^{r-1}C \\\\\n",
    "\\frac{\\partial^2 u}{\\partial e_0^2} &= 0\n",
    "\\end{align*} $$\n",
    "\n",
    "Oh no.. The determinant is negative, so there's a positive eigenvalue. Therefore the solution would be on the edges :(\n",
    "    \n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
